**File:** `mediation-ddls\mnaas_cbf_gnv_invoice_generation.hql`  

---

## 1. Summary
This Hive DDL script creates an **external table** `mnaas.cbf_gnv_invoice_generation` that exposes invoice‑level data produced by the CBF (Charging Billing Framework) and Geneva billing systems. The table is stored as plain‑text files on HDFS, delimited by the caret (`^`) character, and is intended for downstream billing, reporting, and reconciliation jobs that consume invoice headers, charge breakdowns, tax information, and currency conversion details.

---

## 2. Core Objects Defined

| Object | Type | Responsibility |
|--------|------|-----------------|
| `cbf_gnv_invoice_generation` | External Hive table (`mnaas` database) | Provides a read‑only view of invoice records generated by CBF/Geneva; columns capture organization, product, charge types, dates, amounts (both billing currency and USD), tax, status, and conversion metadata. |
| `ROW FORMAT SERDE` | `LazySimpleSerDe` | Parses the caret‑delimited text files into Hive columns. |
| `LOCATION` | HDFS path `hdfs://NN-HA1/user/hive/warehouse/mnaas.db/cbf_gnv_invoice_generation` | Physical storage location of the source files. |
| `TBLPROPERTIES` | Various Hive/Impala metadata (e.g., `external.table.purge`, `impala.events.*`) | Controls table lifecycle, statistics, and catalog integration. |

*No procedural code (functions, procedures, or scripts) is present in this file; it is a pure DDL definition.*

---

## 3. Inputs, Outputs & Side Effects

| Aspect | Details |
|--------|---------|
| **Input data** | Text files residing in the HDFS location above. Each line must contain 33 caret‑separated fields matching the column order defined. |
| **Output** | Hive metadata (table definition) that downstream queries can read. No data is written or transformed by this script itself. |
| **Side effects** | - Registers the external table in the Hive Metastore.<br>- Because `external.table.purge='true'`, dropping the table will also delete the underlying HDFS files (risk). |
| **Assumptions** | - The HDFS directory exists and is populated by the CBF/Geneva invoice export process.<br>- All fields are stored as strings; downstream jobs will cast/convert as needed.<br>- The caret (`^`) delimiter is stable across all source files.<br>- The Hive/Impala services have read permission on the HDFS path. |
| **External dependencies** | - HDFS Namenode (`NN-HA1`).<br>- Hive Metastore (for table registration).<br>- Impala catalog (properties indicate Impala integration).<br>- Upstream CBF/Geneva batch job that writes the source files. |

---

## 4. Integration with the Rest of the Mediation Suite

| Connected component | How it links |
|----------------------|--------------|
| **Other `mnaas` billing tables** (e.g., `mnaas_billing_traffic_usage`, `mnaas_billing_suspended_sims`, etc.) | Queries that join invoice headers with usage, tolling, or suspension data use the common `org_no` / `invoice_no` keys. |
| **Billing ETL pipelines** (typically Spark/MapReduce jobs) | Read from this external table to enrich invoice records with usage details, calculate revenue, or generate downstream reports. |
| **Reporting layer (Impala/BI tools)** | The table is exposed to Impala via the catalog properties, allowing analysts to query invoice data directly. |
| **Data archival / purge jobs** | May reference the `view_refresh_date` column to determine when data can be archived or removed. |
| **Currency conversion service** | The columns `conv_rate_from_billing_curr_to_usd` and `conversion_rate_date` are populated by an upstream service that fetches FX rates; downstream jobs rely on these values for USD reporting. |

*Because all DDL files live under `mediation-ddls`, the naming convention (`mnaas_…`) indicates they belong to the same logical schema and are often referenced together in batch scripts (`run_all_ddl.sh`, CI pipelines, etc.).*

---

## 5. Operational Risks & Mitigations

| Risk | Impact | Recommended Mitigation |
|------|--------|------------------------|
| **Schema drift** – upstream CBF/Geneva adds/removes columns without updating this DDL. | Query failures, data loss. | Implement a schema‑validation step in the ingestion pipeline; version the DDL and enforce compatibility checks. |
| **Delimiter change** – source files switch to a different delimiter. | Mis‑parsed rows, null values. | Store delimiter as a configurable variable (e.g., `${INVOICE_DELIM}`) and validate a sample file before table creation. |
| **External table purge** – accidental `DROP TABLE` removes raw files. | Irrecoverable loss of invoice data. | Restrict DROP privileges; add a safeguard script that disables `external.table.purge` in non‑prod environments. |
| **Permission issues** – Hive/Impala users lack read access to the HDFS path. | Jobs stall, empty result sets. | Audit HDFS ACLs; document required service accounts in a central config file. |
| **Stale data** – source files are not refreshed, but the table is queried as if they are current. | Incorrect billing/reports. | Use the `view_refresh_date` column to drive freshness checks; schedule a monitoring job that alerts if the date is older than a threshold. |

---

## 6. Running / Debugging the Script

1. **Execute the DDL**  
   ```bash
   hive -f mediation-ddls/mnaas_cbf_gnv_invoice_generation.hql
   # or, for Impala:
   impala-shell -i <impala-host> -f mediation-ddls/mnaas_cbf_gnv_invoice_generation.hql
   ```

2. **Verify table creation**  
   ```sql
   SHOW CREATE TABLE mnaas.cbf_gnv_invoice_generation;
   DESCRIBE FORMATTED mnaas.cbf_gnv_invoice_generation;
   ```

3. **Inspect sample data**  
   ```sql
   SELECT * FROM mnaas.cbf_gnv_invoice_generation LIMIT 10;
   ```

4. **Check underlying files** (HDFS)  
   ```bash
   hdfs dfs -ls /user/hive/warehouse/mnaas.db/cbf_gnv_invoice_generation
   hdfs dfs -cat /user/hive/warehouse/mnaas.db/cbf_gnv_invoice_generation/part-00000
   ```

5. **Debug common issues**  
   - *Empty result set*: Verify that the source directory contains files and that the delimiter matches `^`.  
   - *Column misalignment*: Compare the number of fields in a raw line (`awk -F'^' '{print NF}'`) with the 33 columns defined.  
   - *Permission errors*: Check Hive Metastore logs and HDFS ACLs for the service account used by the query engine.

---

## 7. External Configuration / Environment Variables

| Config Item | Usage |
|-------------|-------|
| `NN-HA1` (namenode hostname) | Hard‑coded in the `LOCATION` URI; typically derived from the cluster’s DNS or a configuration management system. |
| `HIVE_CONF_DIR` / `IMPALA_CONF_DIR` | Not referenced directly in the script but required for the Hive/Impala client to locate metastore and catalog settings. |
| `INVOICE_DELIM` (suggested) | Not present; could be introduced to make the delimiter configurable. |
| `TABLE_PURGE_ENABLED` (suggested) | Could control the `external.table.purge` property per environment (dev vs prod). |

If the production environment uses a templating engine (e.g., Jinja, Velocity) to inject values, the script may be rendered with those variables before execution.

---

## 8. Suggested Improvements (TODO)

1. **Data Types & Partitioning** – Convert columns that represent dates (`invoice_date`, `sales_from_date`, etc.) and numeric amounts (`one_time_charges`, `invtotal_usd`, …) to appropriate Hive types (`date`, `decimal`). Add a partition on `invoice_date` (or `view_refresh_date`) to improve query performance and enable incremental loads.

2. **Externalize Delimiter & Purge Flag** – Replace the hard‑coded caret delimiter and `external.table.purge='true'` with environment‑driven variables so that dev, test, and prod can have different settings without editing the DDL. Example:
   ```sql
   WITH SERDEPROPERTIES (
     'field.delim'='${INVOICE_DELIM}',
     'serialization.format'='${INVOICE_DELIM}'
   )
   TBLPROPERTIES (
     'external.table.purge'='${TABLE_PURGE_ENABLED}'
   )
   ```

---