**High‑Level Documentation – `move-mediation-scripts/bin/truncate_table_api_med_data.sh`**

---

### 1. Summary
`truncate_table_api_med_data.sh` is a minimal wrapper that issues a Hive/Impala SQL batch to **remove all rows from the `api_med_data` table** and commit the change. It is intended to be executed by an external client (e.g., `impala-shell -f truncate_table_api_med_data.sh` or `hive -f …`) as part of the nightly or on‑demand data‑load orchestration pipeline that refreshes API‑mediation data. By truncating the table first, downstream loaders can safely repopulate it without having to handle duplicate or stale rows.

---

### 2. Core Elements & Responsibilities
| Element | Type | Responsibility |
|---------|------|-----------------|
| `commit;` | SQL command | Forces the current transaction to be persisted before the truncate (ensures any prior DDL/DML in the same session is saved). |
| `truncate table api_med_data;` | SQL command | Deletes all rows from `api_med_data` efficiently (metadata‑only operation). |
| `exit;` | SQL command | Terminates the SQL session cleanly when run via a CLI client. |

*There are no Bash functions or classes in this file; its sole purpose is to be fed to a Hive/Impala client.*

---

### 3. Inputs, Outputs, Side Effects & Assumptions
| Category | Details |
|----------|---------|
| **Inputs** | None directly. The script assumes the client invoking it is already authenticated and connected to the correct Hive/Impala cluster and database (default or set via `USE <db>` before execution). |
| **Outputs** | No file or console output is generated by the script itself. Success/failure is reported by the invoking client (exit code, standard error). |
| **Side Effects** | - All rows in `api_med_data` are permanently removed.<br>- Transaction is committed, making the truncation visible to other sessions immediately. |
| **Assumptions** | - The `api_med_data` table exists and the user has `DROP`/`TRUNCATE` privileges.<br>- No foreign‑key or cascade constraints prevent truncation (Hive/Impala typically do not enforce FK).<br>- The table is not being concurrently read/written by another job; truncation is coordinated upstream (e.g., via a lock file or process‑status flag). |
| **External Services** | Hive Metastore / Impala daemon (via the client that runs the script). No direct network calls, SFTP, or API endpoints are used. |

---

### 4. Integration Points (How it Connects to the Rest of the System)
| Connected Component | Interaction |
|---------------------|-------------|
| **Data‑load orchestrators** (e.g., `service_based_charges.sh`, `runGBS.sh`, `runMLNS.sh`) | These higher‑level scripts typically invoke `truncate_table_api_med_data.sh` **just before** they start a bulk load (Java loader, Spark job, Sqoop, etc.) to guarantee a clean target table. |
| **Scheduler / Cron** | The script is usually called from a scheduled job (e.g., nightly at 02:00 UTC) via a wrapper such as `hive -f truncate_table_api_med_data.sh`. |
| **Process‑status / lock files** | Other orchestration scripts maintain a status file (e.g., `api_med_data_status.txt`) to enforce single‑instance execution; this script is expected to run only when the lock is held. |
| **Monitoring / Alerting** | Failure of the truncate (non‑zero exit code) is captured by the caller and may trigger email/SDP alerts, similar to other scripts in the suite. |
| **Downstream consumers** (BI dashboards, reporting jobs) | They assume the table is refreshed daily; truncation is part of the data‑refresh contract. |

---

### 5. Operational Risks & Recommended Mitigations
| Risk | Impact | Mitigation |
|------|--------|------------|
| **Accidental data loss** – truncating the wrong table or running out of schedule. | Complete loss of `api_med_data` rows for the day. | - Enforce explicit `USE <schema>` before truncate (add `USE mnaas;` in the script).<br>- Guard with a lock file or status flag checked by the caller.<br>- Include a sanity check (e.g., `SHOW CREATE TABLE api_med_data;`) before truncation in the wrapper. |
| **Concurrent access** – another job reads the table while it is being truncated. | Inconsistent query results, possible job failures. | - Serialize access via a central orchestrator (e.g., Airflow, Oozie) or a simple file‑based semaphore.<br>- Schedule truncation at a time when no downstream jobs run. |
| **Permission errors** – user lacks truncate rights. | Job aborts, downstream load fails. | - Verify user privileges during deployment.<br>- Capture exit code and surface a clear error message in the calling script. |
| **Missing table** – schema change removes `api_med_data`. | Script exits with error; downstream load may target a non‑existent table. | - Add a pre‑flight `DESCRIBE api_med_data;` check and fail fast with a descriptive log. |
| **Uncommitted prior work** – if the client had uncommitted DML before `commit;`, those changes become visible before the truncate, potentially causing temporary data inconsistency. | Brief window of inconsistent state. | - Ensure the caller runs the truncate in a fresh session or after all prior work is completed. |

---

### 6. Running / Debugging the Script
1. **Typical invocation (from a Bash wrapper):**  
   ```bash
   # Example wrapper (run_truncate_api_med_data.sh)
   IMPALA_HOST="impala-prod.example.com"
   impala-shell -i "$IMPALA_HOST" -f "$(dirname "$0")/truncate_table_api_med_data.sh"
   if [ $? -ne 0 ]; then
       echo "ERROR: Truncate of api_med_data failed" >&2
       exit 1
   fi
   ```
2. **Ad‑hoc manual run:**  
   ```bash
   impala-shell -i impala-prod.example.com -q "USE mnaas; $(cat truncate_table_api_med_data.sh)"
   ```
3. **Debugging steps:**  
   - Add `-B` (batch mode) and `-v` (verbose) flags to `impala-shell` to see the exact statements sent.  
   - Check the exit code (`$?`). Non‑zero indicates failure; inspect `stderr` for messages like “Table not found” or “Permission denied”.  
   - Verify the table is empty after execution:  
     ```bash
     impala-shell -i $IMPALA_HOST -q "SELECT COUNT(*) FROM api_med_data;"
     ```
   - Review Hive Metastore logs if the truncate appears to hang.

---

### 7. External Configuration / Environment Variables
| Variable / File | Purpose |
|-----------------|---------|
| `IMPALA_HOST` (or equivalent) | Hostname of the Impala daemon used by the caller. Not referenced directly in this script but required by the wrapper that launches it. |
| `HIVE_CONF_DIR` / `IMPALA_CONF_DIR` | May be needed by the client to locate authentication credentials (Kerberos keytab, SSL certs). |
| `PATH` / `IMPALA_SHELL` | Determines which `impala-shell` binary is invoked. |
| **No internal references** – the script itself contains only raw SQL; any environment‑specific values must be supplied by the invoking process. |

---

### 8. Suggested Improvements (TODO)
1. **Add explicit schema selection** – prepend `USE <target_schema>;` to avoid accidental truncation of a similarly‑named table in another database.  
2. **Wrap in a Bash guard** – create a thin wrapper that checks table existence and logs the operation (timestamp, user, host) before issuing the truncate, improving auditability and safety.  

--- 

*End of documentation.*